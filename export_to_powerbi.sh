#!/bin/bash

# Power BI æ•°æ®å¯¼å‡ºè„šæœ¬
# ç”¨æ³•: 
#   æ‰‹åŠ¨å¯¼å‡º: ./export_to_powerbi.sh
#   è®¾ç½®å®šæ—¶: ./export_to_powerbi.sh --setup-cron
#   ç§»é™¤å®šæ—¶: ./export_to_powerbi.sh --remove-cron

# å¤„ç†å‘½ä»¤è¡Œå‚æ•°
if [ "$1" = "--setup-cron" ]; then
    echo "âš™ï¸  è®¾ç½®å®šæ—¶è‡ªåŠ¨å¯¼å‡º..."
    echo ""
    
    # è·å–è„šæœ¬çš„ç»å¯¹è·¯å¾„
    SCRIPT_PATH="$(cd "$(dirname "$0")" && pwd)/$(basename "$0")"
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å®šæ—¶ä»»åŠ¡
    if crontab -l 2>/dev/null | grep -q "$SCRIPT_PATH"; then
        echo "âš ï¸  å®šæ—¶ä»»åŠ¡å·²å­˜åœ¨ï¼"
        echo ""
        echo "å½“å‰è®¾ç½®ï¼š"
        crontab -l | grep "$SCRIPT_PATH"
        echo ""
        echo "å¦‚éœ€é‡æ–°è®¾ç½®ï¼Œè¯·å…ˆè¿è¡Œ: $0 --remove-cron"
        exit 0
    fi
    
    # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨3ç‚¹è¿è¡Œï¼Œåœ¨ Airflow DAG è¿è¡Œä¹‹åï¼‰
    (crontab -l 2>/dev/null; echo "0 3 * * * $SCRIPT_PATH >> /Users/anthony/Desktop/DataEngineerCourse/powerbi_export.log 2>&1") | crontab -
    
    echo "âœ… å®šæ—¶ä»»åŠ¡è®¾ç½®æˆåŠŸï¼"
    echo ""
    echo "ğŸ“… è®¡åˆ’ï¼š"
    echo "   â€¢ æ¯å¤©å‡Œæ™¨ 3:00 è‡ªåŠ¨å¯¼å‡ºæ•°æ®"
    echo "   â€¢ æ—¥å¿—æ–‡ä»¶: /Users/anthony/Desktop/DataEngineerCourse/powerbi_export.log"
    echo ""
    echo "æŸ¥çœ‹å½“å‰å®šæ—¶ä»»åŠ¡ï¼š"
    crontab -l | grep "$SCRIPT_PATH"
    echo ""
    exit 0
fi

if [ "$1" = "--remove-cron" ]; then
    echo "ğŸ—‘ï¸  ç§»é™¤å®šæ—¶è‡ªåŠ¨å¯¼å‡º..."
    
    # è·å–è„šæœ¬çš„ç»å¯¹è·¯å¾„
    SCRIPT_PATH="$(cd "$(dirname "$0")" && pwd)/$(basename "$0")"
    
    # ç§»é™¤å®šæ—¶ä»»åŠ¡
    crontab -l 2>/dev/null | grep -v "$SCRIPT_PATH" | crontab -
    
    echo "âœ… å®šæ—¶ä»»åŠ¡å·²ç§»é™¤ï¼"
    exit 0
fi

echo "ğŸ”„ å¼€å§‹å¯¼å‡º Power BI æ•°æ®..."
echo "â° $(date '+%Y-%m-%d %H:%M:%S')"
echo ""

# è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_FILE="/Users/anthony/Desktop/youtube_powerbi_data.csv"

# ä»æ•°æ®åº“å¯¼å‡ºæ•°æ®
docker exec postgres psql -U postgres -d elt_db -c "COPY (
    SELECT 
        \"Video_ID\" as video_id,
        \"Video_Title\" as video_title,
        \"Upload_Date\" as upload_date,
        EXTRACT(YEAR FROM \"Upload_Date\") as upload_year,
        EXTRACT(MONTH FROM \"Upload_Date\") as upload_month,
        TO_CHAR(\"Upload_Date\", 'YYYY-MM') as upload_month_name,
        \"Duration\" as duration,
        EXTRACT(EPOCH FROM \"Duration\"::time) as duration_seconds,
        CASE 
            WHEN EXTRACT(EPOCH FROM \"Duration\"::time) <= 60 THEN 'Shorts'
            ELSE 'Normal'
        END as video_type,
        \"View_Count\" as view_count,
        \"Like_Count\" as like_count,
        \"Comment_Count\" as comment_count,
        ROUND(CAST(\"Like_Count\" AS NUMERIC) / NULLIF(\"View_Count\", 0) * 100, 2) as like_rate,
        ROUND(CAST(\"Comment_Count\" AS NUMERIC) / NULLIF(\"View_Count\", 0) * 100, 2) as comment_rate,
        ROUND(CAST(\"Like_Count\" + \"Comment_Count\" AS NUMERIC) / NULLIF(\"View_Count\", 0) * 100, 2) as engagement_rate
    FROM core.yt_api
    ORDER BY \"Upload_Date\" DESC
) TO STDOUT WITH CSV HEADER;" > "$OUTPUT_FILE"

# æ£€æŸ¥æ˜¯å¦æˆåŠŸ
if [ $? -eq 0 ]; then
    # è·å–è®°å½•æ•°
    RECORDS=$(tail -n +2 "$OUTPUT_FILE" | wc -l | xargs)
    FILE_SIZE=$(ls -lh "$OUTPUT_FILE" | awk '{print $5}')
    
    echo "âœ… å¯¼å‡ºæˆåŠŸï¼"
    echo ""
    echo "ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š"
    echo "   â€¢ è®°å½•æ•°: $RECORDS æ¡"
    echo "   â€¢ æ–‡ä»¶å¤§å°: $FILE_SIZE"
    echo "   â€¢ æ–‡ä»¶ä½ç½®: $OUTPUT_FILE"
    echo ""
    echo "ğŸ“¤ ä¸‹ä¸€æ­¥ï¼š"
    echo "   1. æ‰“å¼€ https://app.powerbi.com"
    echo "   2. åˆ é™¤æ—§çš„æ•°æ®é›†"
    echo "   3. ä¸Šä¼ æ–°çš„ CSV æ–‡ä»¶"
    echo ""
else
    echo "âŒ å¯¼å‡ºå¤±è´¥ï¼è¯·æ£€æŸ¥ Docker å®¹å™¨æ˜¯å¦è¿è¡Œã€‚"
    exit 1
fi

